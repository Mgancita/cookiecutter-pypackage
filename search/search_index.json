{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cookiecutter PyPackage Cookiecutter template for a Python package. Powered by Poetry, GitHub actions, and MkDocs-Material. Introduction Welcome to cookiecutter-pypackage! The creation of this project was inspired by the want for an easy-to-configure repository setup where everything could be done within GitHub. In the current state, the repositories created from the cookiecutter uses only GitHub for continuous integration and continuous deployment (CI/CD) via GitHub Actions. This allows for developers to create, test, and deploy their package(s) in an easy-to-use and easy-to-maintain way. File structure All code developed should go within the directory with your project-name given. The packaging works with a single file of code or multiple modules nested within sub-directories. For an example of structuring that allows for easy imports, check out my bowline package. Features This template has the following features: pytest : Unit and coverage testing flake8 and pylint : Python style checks black : Auto-formatted code mypy : Type checking Poetry : Depedency management and packaging GitHub Actions : Automated CI checks, auto-release to PyPi, and automated version bumping (no more Travis needed) MkDocs-Material : Auto-publish documentation to it's own webpage This is a simple list, for a deep-dive into why and how each feature is used visit feature explanation . If already familiar or just not interested, continue to Getting started .","title":"Introduction"},{"location":"#cookiecutter-pypackage","text":"Cookiecutter template for a Python package. Powered by Poetry, GitHub actions, and MkDocs-Material.","title":"Cookiecutter PyPackage"},{"location":"#introduction","text":"Welcome to cookiecutter-pypackage! The creation of this project was inspired by the want for an easy-to-configure repository setup where everything could be done within GitHub. In the current state, the repositories created from the cookiecutter uses only GitHub for continuous integration and continuous deployment (CI/CD) via GitHub Actions. This allows for developers to create, test, and deploy their package(s) in an easy-to-use and easy-to-maintain way.","title":"Introduction"},{"location":"#file-structure","text":"All code developed should go within the directory with your project-name given. The packaging works with a single file of code or multiple modules nested within sub-directories. For an example of structuring that allows for easy imports, check out my bowline package.","title":"File structure"},{"location":"#features","text":"This template has the following features: pytest : Unit and coverage testing flake8 and pylint : Python style checks black : Auto-formatted code mypy : Type checking Poetry : Depedency management and packaging GitHub Actions : Automated CI checks, auto-release to PyPi, and automated version bumping (no more Travis needed) MkDocs-Material : Auto-publish documentation to it's own webpage This is a simple list, for a deep-dive into why and how each feature is used visit feature explanation . If already familiar or just not interested, continue to Getting started .","title":"Features"},{"location":"advanced/feature_explanation/","text":"Feature Explanation Pytest Pytest is the package used for unit and coverage testing within the cookiecutter. I've chosen it over unittest as I find it easier to use and understand the results of. In addition, I like the native fixture functionality of pytest and the pytest-cov extension (used for coverage testing). Flake8 and Pylint Flake8 and Pylint are both linters developed by the Python Code Quality Authority ( PyCQA ). As pylint is typically more exhaustive I select it for the default. If you want to be excessive (as I am with my repos), add flake8 to be sure the proper style guides are followed. Black Black is my go-to code formatter. Although annoying in the beginning, I've grown to love black as it makes git diffs 100x easier. With strict and opionated formatting, it does all the tedious formatting you're too lazy to do and leaves your pull requests with only the important changes being highlighted. Mypy Mypy is the official checker for type-hinting which was added in Python 3.6. I think type-hinting allows for way better readability of Python code. Additionally, it makes sure that variables being passed throughout your program are being correctly accounted for in terms of their type (passing a string of \"1\" when it should be 1 can cause issues down the line). Poetry Poetry is the dependency manager and packager for the cookiecutter. As I've grown frusturated with older tools for Python packaging (setuptools, tox, etc.) I decided to give Poetry a try and it was 100% worth it. It comprises all the necessary settings into a single pyproject.toml file (instead of setup.py/cfg , requirements.txt , MANIFEST.in , etc.) which has growing use by the above packages (with pylint, pytest, and black already supporting). Poetry is one of the main reasons the CI files are short and sweet and the repository is not overrun with packaging files. Github Actions GitHub Actions is still pretty new to the CI space and is probably the biggest split (with Poetry) I use from most Python repositories. The main reason for using GitHub Actions is it's free (up to 2,000/minutes a month) and it's where my code exists. A lot of open-source projects use TravisCI or other services which I think adds complexity to developing and maintaining a project. MkDocs-Material MkDocs-Material is the theme, builder, and publisher (extending MkDocs) for the documentation. The ease-of-use (I think you're seeing a pattern) of developing and deploying the documentation is a big win. Being able to edit the .md files and see the changes in real-time is a huge win. Furthermore, I think the resulting pages are the most visually appealing of any documentation framework I've worked with. Note an ideal state would be to have versioning for the documentation but you have to be an MkDocs-Material insider for that at the moment so it isn't supported by default. Development process Although this isn't a feature per-se, I think it's important to address as it's how I built the cookiecutter structure. The main drive behind having the CI checks on the main and development branches is so these are typically \"protected\" from having bad code. In addition, having the test pypi before pypi allows for user-testing of a new release without pushing out code that isn't ready for production. Lastly, I have the documentation auto-publish when main is updated as I only put code to main when it's ready to be released.","title":"Feature explanation"},{"location":"advanced/feature_explanation/#feature-explanation","text":"","title":"Feature Explanation"},{"location":"advanced/feature_explanation/#pytest","text":"Pytest is the package used for unit and coverage testing within the cookiecutter. I've chosen it over unittest as I find it easier to use and understand the results of. In addition, I like the native fixture functionality of pytest and the pytest-cov extension (used for coverage testing).","title":"Pytest"},{"location":"advanced/feature_explanation/#flake8-and-pylint","text":"Flake8 and Pylint are both linters developed by the Python Code Quality Authority ( PyCQA ). As pylint is typically more exhaustive I select it for the default. If you want to be excessive (as I am with my repos), add flake8 to be sure the proper style guides are followed.","title":"Flake8 and Pylint"},{"location":"advanced/feature_explanation/#black","text":"Black is my go-to code formatter. Although annoying in the beginning, I've grown to love black as it makes git diffs 100x easier. With strict and opionated formatting, it does all the tedious formatting you're too lazy to do and leaves your pull requests with only the important changes being highlighted.","title":"Black"},{"location":"advanced/feature_explanation/#mypy","text":"Mypy is the official checker for type-hinting which was added in Python 3.6. I think type-hinting allows for way better readability of Python code. Additionally, it makes sure that variables being passed throughout your program are being correctly accounted for in terms of their type (passing a string of \"1\" when it should be 1 can cause issues down the line).","title":"Mypy"},{"location":"advanced/feature_explanation/#poetry","text":"Poetry is the dependency manager and packager for the cookiecutter. As I've grown frusturated with older tools for Python packaging (setuptools, tox, etc.) I decided to give Poetry a try and it was 100% worth it. It comprises all the necessary settings into a single pyproject.toml file (instead of setup.py/cfg , requirements.txt , MANIFEST.in , etc.) which has growing use by the above packages (with pylint, pytest, and black already supporting). Poetry is one of the main reasons the CI files are short and sweet and the repository is not overrun with packaging files.","title":"Poetry"},{"location":"advanced/feature_explanation/#github-actions","text":"GitHub Actions is still pretty new to the CI space and is probably the biggest split (with Poetry) I use from most Python repositories. The main reason for using GitHub Actions is it's free (up to 2,000/minutes a month) and it's where my code exists. A lot of open-source projects use TravisCI or other services which I think adds complexity to developing and maintaining a project.","title":"Github Actions"},{"location":"advanced/feature_explanation/#mkdocs-material","text":"MkDocs-Material is the theme, builder, and publisher (extending MkDocs) for the documentation. The ease-of-use (I think you're seeing a pattern) of developing and deploying the documentation is a big win. Being able to edit the .md files and see the changes in real-time is a huge win. Furthermore, I think the resulting pages are the most visually appealing of any documentation framework I've worked with. Note an ideal state would be to have versioning for the documentation but you have to be an MkDocs-Material insider for that at the moment so it isn't supported by default.","title":"MkDocs-Material"},{"location":"advanced/feature_explanation/#development-process","text":"Although this isn't a feature per-se, I think it's important to address as it's how I built the cookiecutter structure. The main drive behind having the CI checks on the main and development branches is so these are typically \"protected\" from having bad code. In addition, having the test pypi before pypi allows for user-testing of a new release without pushing out code that isn't ready for production. Lastly, I have the documentation auto-publish when main is updated as I only put code to main when it's ready to be released.","title":"Development process"},{"location":"getting-started/configure_github_repo/","text":"Configure GitHub repository Setup branches Now that we've pushed our repository to GitHub we'll see a main branch with all the code but you rarely want to push code directly to main. To mitigate this, lets create a development branch for which to actively develop code and then move it to main once we think it's safe for production. To do so, simply: Click on the \"main\" dropdown button your repo's homepage Type in \"development\" in the search bar Select \"Create branch: development from main\". Note if 'development' is not used. You must change the branch reference in certain files within the '.github/workflows' directory for CI checks to work. As seen with main, you'll see Actions being run for development. Additionally, whenever you open a pull request (PR) from development to main, the checks will automatically run to make sure the code is safe for merging. That is the base needed for the CI system to work. If you wish to add further protection to your repository visit the Settings -> Branches section of your repo. This will allow you to add things like not allow code into a certain branch until it passes all CI checks and/or has been approved by at least 1 admin/contributer. Setup documentation page As mentioned in the previous section, your repo magically (done by Github Actions) created a gh-pages branch. All the files in that branch are automatically generated from the files in the repository's docs folder. For more information on how to add pages to this documentation visit MkDocs-Material docs . To publish the docs to your own github site do the following: Go to \"Settings\" section. Scroll down to \"GitHub Pages\" section. Within the \"Source\" section select gh-pages branch and /(root) . Click \"Save\" button. Scroll back down to \"GitHub Pages\" and a link should be given for where your docs will be published (wait a few minutes for publication). In addition, this link can be added in the About section of your repository under \"website\" to display the link in a nice area. Now your repository has been properly configured! With proper code quality checks and automatically publishing documentation, you're just one more step away to having the infrastructure to develop an open-source Python package. Setting up the Navigation system Because the docs only start with an index.md file, there's no need / way to setup a more complete navigation system (otherwise known as the page tree). To set this up, reference the nav section of this cookiecutter's mkdocs.yml file. Note that each highest level list item becomes part of the top nav and then all nested items are shown within each section.","title":"Configure GitHub repository"},{"location":"getting-started/configure_github_repo/#configure-github-repository","text":"","title":"Configure GitHub repository"},{"location":"getting-started/configure_github_repo/#setup-branches","text":"Now that we've pushed our repository to GitHub we'll see a main branch with all the code but you rarely want to push code directly to main. To mitigate this, lets create a development branch for which to actively develop code and then move it to main once we think it's safe for production. To do so, simply: Click on the \"main\" dropdown button your repo's homepage Type in \"development\" in the search bar Select \"Create branch: development from main\". Note if 'development' is not used. You must change the branch reference in certain files within the '.github/workflows' directory for CI checks to work. As seen with main, you'll see Actions being run for development. Additionally, whenever you open a pull request (PR) from development to main, the checks will automatically run to make sure the code is safe for merging. That is the base needed for the CI system to work. If you wish to add further protection to your repository visit the Settings -> Branches section of your repo. This will allow you to add things like not allow code into a certain branch until it passes all CI checks and/or has been approved by at least 1 admin/contributer.","title":"Setup branches"},{"location":"getting-started/configure_github_repo/#setup-documentation-page","text":"As mentioned in the previous section, your repo magically (done by Github Actions) created a gh-pages branch. All the files in that branch are automatically generated from the files in the repository's docs folder. For more information on how to add pages to this documentation visit MkDocs-Material docs . To publish the docs to your own github site do the following: Go to \"Settings\" section. Scroll down to \"GitHub Pages\" section. Within the \"Source\" section select gh-pages branch and /(root) . Click \"Save\" button. Scroll back down to \"GitHub Pages\" and a link should be given for where your docs will be published (wait a few minutes for publication). In addition, this link can be added in the About section of your repository under \"website\" to display the link in a nice area. Now your repository has been properly configured! With proper code quality checks and automatically publishing documentation, you're just one more step away to having the infrastructure to develop an open-source Python package.","title":"Setup documentation page"},{"location":"getting-started/configure_github_repo/#setting-up-the-navigation-system","text":"Because the docs only start with an index.md file, there's no need / way to setup a more complete navigation system (otherwise known as the page tree). To set this up, reference the nav section of this cookiecutter's mkdocs.yml file. Note that each highest level list item becomes part of the top nav and then all nested items are shown within each section.","title":"Setting up the Navigation system"},{"location":"getting-started/connect_to_remote_repo/","text":"Connect to remote repository on GitHub Initialize local repository Now lets initialize a git repository within the created project for version control. First, move into the directory of the project. $ cd project-name/ Then, setup poetry dependency manager, $ pip install poetry && poetry install For more info on poetry, check out their docs . Lastly, initialize the repo. $ git init This will create a git repository within the project. Don't do anything just yet with it. Create remote repository on GitHub If it hasn't already been created, we'll have to create a remote repository on GitHub. To do so, follow the steps: Go to GitHub's create new repository page . Fill in the name and description with the values given at project creation. Make your choice of Public or Private. Leave all other boxes unchecked. Sync local repository with GitHub Add remote link Let's start with adding the newly created remote repository to the local repostiory so it knows where to push changes to. To do so run: $ git remote add origin link_to_repo Make sure to replace link_to_repo with your repo's url. It can be found on your repository's home page under the green \"Code\" dropdown menu button. Push local files to remote Now that the remote repository is setup let's get all the code generated by the cookiecutter there. First let's add all the project files to the local repository (remember we only initalized an empty repository): $ git add . Next, commit those changes: $ git commit -m \"Initialize repo\" Then, we name the current branch (with the files) to main : $ git branch -M main Note if main is not used. You must change the branch reference in certain files within the '.github/workflows' directory for CI checks to work. Finally, lets push it to GitHub: $ git push -u origin main That's it! Now you should see your GitHub repository with all the starter files. In addition, check out the \"Actions\" section of the repository to see the CI checks (docs deployment and code quality) being run. Once these are done, you'll see a gh-pages branch was created with odd files. Don't worry about that for now, it's the automatically generated documenation and we'll cover how to have that hosted on your own webpage in the next section. Continue on to see how to configure your GitHub repository to work optimally with the cookiecutter setup!","title":"Connect to remote repository"},{"location":"getting-started/connect_to_remote_repo/#connect-to-remote-repository-on-github","text":"","title":"Connect to remote repository on GitHub"},{"location":"getting-started/connect_to_remote_repo/#initialize-local-repository","text":"Now lets initialize a git repository within the created project for version control. First, move into the directory of the project. $ cd project-name/ Then, setup poetry dependency manager, $ pip install poetry && poetry install For more info on poetry, check out their docs . Lastly, initialize the repo. $ git init This will create a git repository within the project. Don't do anything just yet with it.","title":"Initialize local repository"},{"location":"getting-started/connect_to_remote_repo/#create-remote-repository-on-github","text":"If it hasn't already been created, we'll have to create a remote repository on GitHub. To do so, follow the steps: Go to GitHub's create new repository page . Fill in the name and description with the values given at project creation. Make your choice of Public or Private. Leave all other boxes unchecked.","title":"Create remote repository on GitHub"},{"location":"getting-started/connect_to_remote_repo/#sync-local-repository-with-github","text":"","title":"Sync local repository with GitHub"},{"location":"getting-started/connect_to_remote_repo/#add-remote-link","text":"Let's start with adding the newly created remote repository to the local repostiory so it knows where to push changes to. To do so run: $ git remote add origin link_to_repo Make sure to replace link_to_repo with your repo's url. It can be found on your repository's home page under the green \"Code\" dropdown menu button.","title":"Add remote link"},{"location":"getting-started/connect_to_remote_repo/#push-local-files-to-remote","text":"Now that the remote repository is setup let's get all the code generated by the cookiecutter there. First let's add all the project files to the local repository (remember we only initalized an empty repository): $ git add . Next, commit those changes: $ git commit -m \"Initialize repo\" Then, we name the current branch (with the files) to main : $ git branch -M main Note if main is not used. You must change the branch reference in certain files within the '.github/workflows' directory for CI checks to work. Finally, lets push it to GitHub: $ git push -u origin main That's it! Now you should see your GitHub repository with all the starter files. In addition, check out the \"Actions\" section of the repository to see the CI checks (docs deployment and code quality) being run. Once these are done, you'll see a gh-pages branch was created with odd files. Don't worry about that for now, it's the automatically generated documenation and we'll cover how to have that hosted on your own webpage in the next section. Continue on to see how to configure your GitHub repository to work optimally with the cookiecutter setup!","title":"Push local files to remote"},{"location":"getting-started/create_local_project/","text":"Getting started Create local project Setup cookiecutter To start, install the latest Cookiecutter if you haven't installed it yet (this requires Cookiecutter 1.4.0 or higher): $ pip install -U cookiecutter>=1.4.0 Create local project via cookiecutter Now you can use cookiecutter to generate your Python package project: $ cookiecutter https://github.com/mgancita/cookiecutter-pypackage.git If you will be publishing to PyPI, make sure the name of your project isn't already taken as you will be rejected from uploading to an already existing package. Now you should have a project directory for your code! Continue on to see how to get it onto GitHub.","title":"Create local project"},{"location":"getting-started/create_local_project/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/create_local_project/#create-local-project","text":"","title":"Create local project"},{"location":"getting-started/create_local_project/#setup-cookiecutter","text":"To start, install the latest Cookiecutter if you haven't installed it yet (this requires Cookiecutter 1.4.0 or higher): $ pip install -U cookiecutter>=1.4.0","title":"Setup cookiecutter"},{"location":"getting-started/create_local_project/#create-local-project-via-cookiecutter","text":"Now you can use cookiecutter to generate your Python package project: $ cookiecutter https://github.com/mgancita/cookiecutter-pypackage.git If you will be publishing to PyPI, make sure the name of your project isn't already taken as you will be rejected from uploading to an already existing package. Now you should have a project directory for your code! Continue on to see how to get it onto GitHub.","title":"Create local project via cookiecutter"},{"location":"getting-started/publish_to_pypi/","text":"Publish to PyPI Differences in the process Now that we've published to test pypi. PyPI should be cake! Instead of re-writing the process with a few tweaks I'll mention the main differences here for getting to PyPI. Visit PyPI (not test pypi) to create an account. Go to the API tokens section with Account Settings . Generate a new API token and set it as PYPI_TOKEN . Note that it should have a prefix of pypi- before a long token of characters. For release: Select main branch , Set tag version to 0.1.0 , Set release title to v0.1.0 , Do NOT select \"This is pre-release\". The pip command should be: $ pip install your_package_name or $ pip install your_package_name==0.1.0 if you wish to pin the version number. Use your code Lastly, lets see how you would import your code. Lets say you have a package called test_project, with a module called test_file, and within that module a class called TestClass. After pip installing your code, in a Python file you could import the class like so, from test_project.test_file import TestClass And that's it! Checkout the Advanced section if you'd like to learn more about the specific quality checks being used to test the code as well as why certain packages were used over others in this repository.","title":"Publish to PyPI"},{"location":"getting-started/publish_to_pypi/#publish-to-pypi","text":"","title":"Publish to PyPI"},{"location":"getting-started/publish_to_pypi/#differences-in-the-process","text":"Now that we've published to test pypi. PyPI should be cake! Instead of re-writing the process with a few tweaks I'll mention the main differences here for getting to PyPI. Visit PyPI (not test pypi) to create an account. Go to the API tokens section with Account Settings . Generate a new API token and set it as PYPI_TOKEN . Note that it should have a prefix of pypi- before a long token of characters. For release: Select main branch , Set tag version to 0.1.0 , Set release title to v0.1.0 , Do NOT select \"This is pre-release\". The pip command should be: $ pip install your_package_name or $ pip install your_package_name==0.1.0 if you wish to pin the version number.","title":"Differences in the process"},{"location":"getting-started/publish_to_pypi/#use-your-code","text":"Lastly, lets see how you would import your code. Lets say you have a package called test_project, with a module called test_file, and within that module a class called TestClass. After pip installing your code, in a Python file you could import the class like so, from test_project.test_file import TestClass And that's it! Checkout the Advanced section if you'd like to learn more about the specific quality checks being used to test the code as well as why certain packages were used over others in this repository.","title":"Use your code"},{"location":"getting-started/publish_to_test_pypi/","text":"Publish to test PyPI What is PyPI? Great question! Python Package Index ( PyPI ) is where your computer goes (by default) when you pip install a package. By having your package on PyPI (don't worry it's 100% free), anyone can download your code with a single line command. I think that's pretty amazing! Cookiecutter's release process The cookiecutter creates a project which has a release action for release candidates and a seperate one for production releases. The logic for why is as follows, before merging into main (and releasing to production) the developer should develop the code on the development branch. With the development code thought to be ready for production, the developer would create a release candidate (otherwise known as pre-release ) which ships the package to test pypi . This is done so the package can be downloaded and user-tested without messing up the release history of your pypi package. In addition, it's typically recommended to only have production-ready code on your main branch. With this being said, we'll have to create a pypi and test pypi account and configuration to have a robust packaging and testing process. Note the current release process uses username and password while token api key is recommended. I've been having issues getting tokens to work with poetry but it's a main priority to shift to a better system. Create test PyPI account Before we're able to start publishing packages, we'll have to setup accounts. Visit test pypi and sign-up for an account. Setup repository secrets for test PyPI Github Secrets is an amazing tools in which you can inject secret variables into your Github Actions without them being visible to the public, which is especially important for open-source projects. The cookiecutter's out-of-the-box continous deployment process to publish to test pypi looks for a few secret variables so we'll set those here. Navigate to the API tokens section of your Account Settings and generate a token. This token should start with pypi- and be followed by a long sequence of characters and numbers. Add that token as a secret called TEST_PYPI_TOKEN in your repositories secrets. If you use other variable names, you'll have to change the secret references in .github/workflows/test_pypi_publish.yml . Create release candidate The time has come. These are the steps needed to publish to test pypi: Navigate to the Releases section of your repository. Click \"Create a new release\". Set Tag version to 0.1.0-rc0 . Select development branch. Set Release title to Release Candidate: v0.1.0 (or a fun name). Select \"This is a pre-release\" Click \"Publish release\" Wait a few minutes (or watch the Github Action) for it to be published then visit your test pypi projects page to see the release. Install package Now that you code is on test pypi it's as easy as pip install with one extra argument which is --extra-index-url . This allows pip to know to also check test pypi for your code. It should look like this: $ pip install your_package_name==0.1.0rc0 --extra-index-url=https://test.pypi.org/simple/ As there is no release candidates (and therefore no 0.1.0rc0 ) on pypi. This command would not be able to find the given release without the extra-index-url . And there it is! Your own package installable with a single command. Let's move on to see how to get it on PyPI!","title":"Publish to test PyPI"},{"location":"getting-started/publish_to_test_pypi/#publish-to-test-pypi","text":"","title":"Publish to test PyPI"},{"location":"getting-started/publish_to_test_pypi/#what-is-pypi","text":"Great question! Python Package Index ( PyPI ) is where your computer goes (by default) when you pip install a package. By having your package on PyPI (don't worry it's 100% free), anyone can download your code with a single line command. I think that's pretty amazing!","title":"What is PyPI?"},{"location":"getting-started/publish_to_test_pypi/#cookiecutters-release-process","text":"The cookiecutter creates a project which has a release action for release candidates and a seperate one for production releases. The logic for why is as follows, before merging into main (and releasing to production) the developer should develop the code on the development branch. With the development code thought to be ready for production, the developer would create a release candidate (otherwise known as pre-release ) which ships the package to test pypi . This is done so the package can be downloaded and user-tested without messing up the release history of your pypi package. In addition, it's typically recommended to only have production-ready code on your main branch. With this being said, we'll have to create a pypi and test pypi account and configuration to have a robust packaging and testing process. Note the current release process uses username and password while token api key is recommended. I've been having issues getting tokens to work with poetry but it's a main priority to shift to a better system.","title":"Cookiecutter's release process"},{"location":"getting-started/publish_to_test_pypi/#create-test-pypi-account","text":"Before we're able to start publishing packages, we'll have to setup accounts. Visit test pypi and sign-up for an account.","title":"Create test PyPI account"},{"location":"getting-started/publish_to_test_pypi/#setup-repository-secrets-for-test-pypi","text":"Github Secrets is an amazing tools in which you can inject secret variables into your Github Actions without them being visible to the public, which is especially important for open-source projects. The cookiecutter's out-of-the-box continous deployment process to publish to test pypi looks for a few secret variables so we'll set those here. Navigate to the API tokens section of your Account Settings and generate a token. This token should start with pypi- and be followed by a long sequence of characters and numbers. Add that token as a secret called TEST_PYPI_TOKEN in your repositories secrets. If you use other variable names, you'll have to change the secret references in .github/workflows/test_pypi_publish.yml .","title":"Setup repository secrets for test PyPI"},{"location":"getting-started/publish_to_test_pypi/#create-release-candidate","text":"The time has come. These are the steps needed to publish to test pypi: Navigate to the Releases section of your repository. Click \"Create a new release\". Set Tag version to 0.1.0-rc0 . Select development branch. Set Release title to Release Candidate: v0.1.0 (or a fun name). Select \"This is a pre-release\" Click \"Publish release\" Wait a few minutes (or watch the Github Action) for it to be published then visit your test pypi projects page to see the release.","title":"Create release candidate"},{"location":"getting-started/publish_to_test_pypi/#install-package","text":"Now that you code is on test pypi it's as easy as pip install with one extra argument which is --extra-index-url . This allows pip to know to also check test pypi for your code. It should look like this: $ pip install your_package_name==0.1.0rc0 --extra-index-url=https://test.pypi.org/simple/ As there is no release candidates (and therefore no 0.1.0rc0 ) on pypi. This command would not be able to find the given release without the extra-index-url . And there it is! Your own package installable with a single command. Let's move on to see how to get it on PyPI!","title":"Install package"}]}